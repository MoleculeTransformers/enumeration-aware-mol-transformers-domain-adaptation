{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecf5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enumeration import SmilesEnumerator\n",
    "from data_reader import DataReader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac480c2",
   "metadata": {},
   "source": [
    "## Prepare Data for Contrastive Learning Using the Enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e8b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script only requires unlabelled SMILES and generates data for contrastive learning\n",
    "\"\"\"\n",
    "\n",
    "def perform_augmentation(dataset_path, out_file_path, smiles_column = \"smiles\", \n",
    "                         labels_column = \"smiles\", n_augmentations = 2):\n",
    "    \n",
    "    data_reader = DataReader(dataset_path, smiles_column, labels_column=labels_column)\n",
    "    smiles_enumerator = SmilesEnumerator(canonical=False, enum=True)\n",
    "    enumerated_triplets   = smiles_enumerator.enumerate_smiles_hard_neg(\n",
    "        data_reader, smiles_column, random_pairs=True, replication_count=n_augmentations)\n",
    "    \n",
    "    print(enumerated_triplets.shape)\n",
    "    enumerated_triplets.to_csv(out_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b62fbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 42478.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "in_file_path = \"data/smiles.csv\"\n",
    "out_file_path = \"data/smiles_for_contrastive_learning.csv\" \n",
    "\n",
    "perform_augmentation(dataset_path=in_file_path, out_file_path=out_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e3c29",
   "metadata": {},
   "source": [
    "## Prepare Data for MTR by computing normalization values (mean, std) of Physicochemical Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6edf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60524d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicoChemcialPropertyExtractor:\n",
    "    \"\"\"Computes RDKit properties on-the-fly.\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.descriptors = [name for name, _ in Chem.Descriptors.descList]\n",
    "        self.descriptors.remove(\"Ipc\")\n",
    "        self.calculator = MolecularDescriptorCalculator(self.descriptors)\n",
    "        self.num_labels = len(self.descriptors)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def _compute_descriptors(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            mol_descriptors = np.full(shape=(self.num_labels), fill_value=0.0)\n",
    "        else:\n",
    "            mol_descriptors = np.array(list(self.calculator.CalcDescriptors(mol)))\n",
    "            mol_descriptors = np.nan_to_num(\n",
    "                mol_descriptors, nan=0.0, posinf=0.0, neginf=0.0\n",
    "            )\n",
    "        assert mol_descriptors.size == self.num_labels\n",
    "\n",
    "        return mol_descriptors\n",
    "\n",
    "    def preprocess(self, feature_dict):\n",
    "        smiles = feature_dict[\"text\"]\n",
    "        batch_encoding = self.tokenizer(\n",
    "            smiles,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.block_size,\n",
    "        )\n",
    "        batch_encoding = {k: torch.tensor(v) for k, v in batch_encoding.items()}\n",
    "\n",
    "        mol_descriptors = self._compute_descriptors(smiles)\n",
    "        batch_encoding[\"label\"] = torch.tensor(mol_descriptors, dtype=torch.float32)\n",
    "\n",
    "        return batch_encoding\n",
    "\n",
    "\n",
    "\n",
    "def get_data_files(train_path):\n",
    "    if os.path.isdir(train_path):\n",
    "        return [\n",
    "            os.path.join(train_path, file_name) for file_name in os.listdir(train_path)\n",
    "        ]\n",
    "    elif os.path.isfile(train_path):\n",
    "        return train_path\n",
    "\n",
    "    raise ValueError(\"Please pass in a proper train path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33a14744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.06it/s]\n"
     ]
    }
   ],
   "source": [
    "## init physicochemical property extractor\n",
    "physicochemical_fingerprint_extractor = PhysicoChemcialPropertyExtractor(tokenizer=None)\n",
    "\n",
    "physicochemical_fingerprints = []\n",
    "for smile in tqdm(smiles):\n",
    "    physicochemical_fingerprints.append(physicochemical_fingerprint_extractor._compute_descriptors(smile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c56fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "physicochemical_fingerprints_np = np.array(physicochemical_fingerprints)\n",
    "\n",
    "# Compute mean and std\n",
    "mean = np.mean(physicochemical_fingerprints_np, axis=0)\n",
    "std = np.std(physicochemical_fingerprints_np, axis=0)\n",
    "\n",
    "## dump the output as json to be used for in pre-training\n",
    "with open(\"data/normalization_values_207.json\", \"w\") as outfile:\n",
    "    json.dump({\n",
    "    \"mean\": list(mean),\n",
    "    \"std\": list(std)\n",
    "    }, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
